{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-Based Filtering Model Development\n",
    "\n",
    "This notebook implements and evaluates content-based recommendation algorithms using movie features like genres, titles, and metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our custom modules\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.data_loader import MovieDataLoader\n",
    "from src.recommenders.content_based import ContentBasedRecommender\n",
    "from src.utils import parse_genres, extract_year_from_title, get_unique_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_loader = MovieDataLoader()\n",
    "movies_df, ratings_df, links_df = data_loader.load_data()\n",
    "\n",
    "print(f\"Dataset loaded:\")\n",
    "print(f\"Movies: {len(movies_df)}\")\n",
    "print(f\"Ratings: {len(ratings_df)}\")\n",
    "print(f\"Users: {ratings_df['userId'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Content Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze content features available\n",
    "print(\"Available content features:\")\n",
    "print(f\"1. Movie titles: {movies_df['title'].notna().sum()} / {len(movies_df)}\")\n",
    "print(f\"2. Genres: {movies_df['genres'].notna().sum()} / {len(movies_df)}\")\n",
    "\n",
    "# Extract additional features\n",
    "movies_enhanced = movies_df.copy()\n",
    "\n",
    "# Extract year from title\n",
    "title_year_data = movies_enhanced['title'].apply(extract_year_from_title)\n",
    "movies_enhanced['clean_title'] = title_year_data.apply(lambda x: x[0])\n",
    "movies_enhanced['year'] = title_year_data.apply(lambda x: x[1])\n",
    "\n",
    "# Parse genres into lists\n",
    "movies_enhanced['genre_list'] = movies_enhanced['genres'].apply(parse_genres)\n",
    "\n",
    "print(f\"\\nEnhanced features:\")\n",
    "print(f\"3. Release years: {movies_enhanced['year'].notna().sum()} / {len(movies_enhanced)}\")\n",
    "print(f\"4. Clean titles: {movies_enhanced['clean_title'].notna().sum()} / {len(movies_enhanced)}\")\n",
    "\n",
    "display(movies_enhanced[['title', 'clean_title', 'year', 'genres', 'genre_list']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Genre-Based Content Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze genre distribution\n",
    "all_genres = get_unique_genres(movies_df)\n",
    "print(f\"Total unique genres: {len(all_genres)}\")\n",
    "print(f\"Genres: {', '.join(all_genres)}\")\n",
    "\n",
    "# Create genre binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_matrix = mlb.fit_transform(movies_enhanced['genre_list'])\n",
    "genre_df = pd.DataFrame(genre_matrix, columns=mlb.classes_, index=movies_enhanced.index)\n",
    "\n",
    "print(f\"\\nGenre matrix shape: {genre_df.shape}\")\n",
    "print(f\"Average genres per movie: {genre_df.sum(axis=1).mean():.2f}\")\n",
    "\n",
    "# Visualize genre co-occurrence\n",
    "genre_corr = genre_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(genre_corr, dtype=bool))\n",
    "sns.heatmap(genre_corr, mask=mask, annot=False, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Genre Co-occurrence Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Most common genre combinations\n",
    "genre_combinations = {}\n",
    "for _, row in movies_enhanced.iterrows():\n",
    "    genres = tuple(sorted(row['genre_list']))\n",
    "    if len(genres) > 1:  # Only combinations\n",
    "        genre_combinations[genres] = genre_combinations.get(genres, 0) + 1\n",
    "\n",
    "top_combinations = sorted(genre_combinations.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(f\"\\nTop 10 Genre Combinations:\")\n",
    "for combo, count in top_combinations:\n",
    "    print(f\"{' + '.join(combo)}: {count} movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TF-IDF Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare content features for TF-IDF\n",
    "def prepare_content_features(movies_df, use_genres=True, use_titles=True, genre_weight=3):\n",
    "    \"\"\"Prepare combined content features for each movie\"\"\"\n",
    "    content_features = []\n",
    "    \n",
    "    for _, movie in movies_df.iterrows():\n",
    "        features = []\n",
    "        \n",
    "        # Add genres (with higher weight)\n",
    "        if use_genres and pd.notna(movie['genres']):\n",
    "            genres = parse_genres(movie['genres'])\n",
    "            # Repeat genres to give them more weight\n",
    "            features.extend(genres * genre_weight)\n",
    "        \n",
    "        # Add title words\n",
    "        if use_titles and pd.notna(movie['title']):\n",
    "            # Clean title (remove year)\n",
    "            clean_title = movie['title']\n",
    "            if '(' in clean_title:\n",
    "                clean_title = clean_title[:clean_title.rfind('(')].strip()\n",
    "            \n",
    "            # Add title words\n",
    "            title_words = clean_title.lower().replace('-', ' ').split()\n",
    "            # Filter out common words that don't add meaning\n",
    "            stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of'}\n",
    "            title_words = [word for word in title_words if word not in stop_words and len(word) > 2]\n",
    "            features.extend(title_words)\n",
    "        \n",
    "        content_features.append(' '.join(features))\n",
    "    \n",
    "    return content_features\n",
    "\n",
    "# Generate content features with different configurations\n",
    "content_configs = [\n",
    "    {'use_genres': True, 'use_titles': False, 'name': 'Genres Only'},\n",
    "    {'use_genres': False, 'use_titles': True, 'name': 'Titles Only'},\n",
    "    {'use_genres': True, 'use_titles': True, 'name': 'Genres + Titles'}\n",
    "]\n",
    "\n",
    "tfidf_results = {}\n",
    "\n",
    "for config in content_configs:\n",
    "    print(f\"\\nProcessing: {config['name']}\")\n",
    "    \n",
    "    # Prepare features\n",
    "    content_features = prepare_content_features(\n",
    "        movies_enhanced, \n",
    "        use_genres=config['use_genres'], \n",
    "        use_titles=config['use_titles']\n",
    "    )\n",
    "    \n",
    "    # Create TF-IDF vectorizer\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=1000,\n",
    "        min_df=2,\n",
    "        max_df=0.8,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words='english'\n",
    "    )\n",
    "    \n",
    "    # Fit and transform\n",
    "    tfidf_matrix = tfidf.fit_transform(content_features)\n",
    "    \n",
    "    print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "    print(f\"Feature names (first 10): {list(tfidf.get_feature_names_out()[:10])}\")\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    # Store results\n",
    "    tfidf_results[config['name']] = {\n",
    "        'vectorizer': tfidf,\n",
    "        'matrix': tfidf_matrix,\n",
    "        'similarity': cosine_sim,\n",
    "        'features': content_features\n",
    "    }\n",
    "    \n",
    "    # Analyze similarity distribution\n",
    "    # Get upper triangle of similarity matrix (excluding diagonal)\n",
    "    upper_tri_indices = np.triu_indices_from(cosine_sim, k=1)\n",
    "    similarity_values = cosine_sim[upper_tri_indices]\n",
    "    \n",
    "    print(f\"Similarity statistics:\")\n",
    "    print(f\"  Mean: {similarity_values.mean():.4f}\")\n",
    "    print(f\"  Std: {similarity_values.std():.4f}\")\n",
    "    print(f\"  Max: {similarity_values.max():.4f}\")\n",
    "    print(f\"  95th percentile: {np.percentile(similarity_values, 95):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Content-Based Recommender Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train content-based recommender\n",
    "content_recommender = ContentBasedRecommender()\n",
    "\n",
    "print(\"Training content-based recommender...\")\n",
    "content_recommender.fit(ratings_df, movies_df, use_genres=True, use_titles=True)\n",
    "\n",
    "print(f\"Model trained successfully!\")\n",
    "print(f\"Feature matrix shape: {content_recommender.feature_matrix.shape}\")\n",
    "print(f\"Similarity matrix shape: {content_recommender.similarity_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Movie-to-Movie Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test movie-to-movie similarity\n",
    "def analyze_movie_similarity(movie_title, n_similar=10):\n",
    "    \"\"\"Analyze similarity for a specific movie\"\"\"\n",
    "    # Find movie ID\n",
    "    movie_match = movies_df[movies_df['title'].str.contains(movie_title, case=False, na=False)]\n",
    "    \n",
    "    if movie_match.empty:\n",
    "        print(f\"Movie '{movie_title}' not found\")\n",
    "        return\n",
    "    \n",
    "    movie_id = movie_match.iloc[0]['movieId']\n",
    "    actual_title = movie_match.iloc[0]['title']\n",
    "    movie_genres = movie_match.iloc[0]['genres']\n",
    "    \n",
    "    print(f\"\\nAnalyzing similarity for: {actual_title}\")\n",
    "    print(f\"Genres: {movie_genres}\")\n",
    "    \n",
    "    # Get similar movies\n",
    "    similar_movies = content_recommender.recommend(\n",
    "        movie_id=movie_id, \n",
    "        n_recommendations=n_similar\n",
    "    )\n",
    "    \n",
    "    if not similar_movies:\n",
    "        print(\"No similar movies found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nTop {n_similar} Similar Movies:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, movie in enumerate(similar_movies, 1):\n",
    "        similarity_score = movie['score']\n",
    "        title = movie['title']\n",
    "        genres = movie['genres']\n",
    "        avg_rating = movie.get('avg_rating', 0)\n",
    "        rating_count = movie.get('rating_count', 0)\n",
    "        \n",
    "        print(f\"{i:2d}. {title}\")\n",
    "        print(f\"    Similarity: {similarity_score:.3f} | Genres: {genres}\")\n",
    "        if avg_rating > 0:\n",
    "            print(f\"    Rating: {avg_rating:.1f}/5.0 ({rating_count} ratings)\")\n",
    "        print()\n",
    "\n",
    "# Test with different movie types\n",
    "test_movies = [\n",
    "    \"Toy Story\",\n",
    "    \"Matrix\",\n",
    "    \"Pulp Fiction\"\n",
    "]\n",
    "\n",
    "for test_movie in test_movies:\n",
    "    analyze_movie_similarity(test_movie, n_similar=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. User-Based Content Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test user-based content recommendations\n",
    "def analyze_user_recommendations(user_id, n_recommendations=10):\n",
    "    \"\"\"Analyze content-based recommendations for a user\"\"\"\n",
    "    \n",
    "    # Get user's rating history\n",
    "    user_ratings = ratings_df[ratings_df['userId'] == user_id]\n",
    "    \n",
    "    if user_ratings.empty:\n",
    "        print(f\"User {user_id} has no ratings\")\n",
    "        return\n",
    "    \n",
    "    # Show user profile\n",
    "    user_movies = user_ratings.merge(movies_df, on='movieId')\n",
    "    \n",
    "    print(f\"\\nUser {user_id} Profile:\")\n",
    "    print(f\"Total ratings: {len(user_ratings)}\")\n",
    "    print(f\"Average rating: {user_ratings['rating'].mean():.2f}\")\n",
    "    print(f\"Rating distribution: {dict(user_ratings['rating'].value_counts().sort_index())}\")\n",
    "    \n",
    "    # Analyze genre preferences\n",
    "    user_genre_prefs = {}\n",
    "    for _, movie in user_movies.iterrows():\n",
    "        genres = parse_genres(movie['genres'])\n",
    "        rating = movie['rating']\n",
    "        \n",
    "        for genre in genres:\n",
    "            if genre not in user_genre_prefs:\n",
    "                user_genre_prefs[genre] = []\n",
    "            user_genre_prefs[genre].append(rating)\n",
    "    \n",
    "    # Calculate average rating per genre\n",
    "    genre_avg_ratings = {\n",
    "        genre: np.mean(ratings) \n",
    "        for genre, ratings in user_genre_prefs.items() \n",
    "        if len(ratings) >= 2  # At least 2 ratings\n",
    "    }\n",
    "    \n",
    "    if genre_avg_ratings:\n",
    "        sorted_genres = sorted(genre_avg_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "        print(f\"\\nGenre Preferences (avg rating):\")\n",
    "        for genre, avg_rating in sorted_genres[:5]:\n",
    "            count = len(user_genre_prefs[genre])\n",
    "            print(f\"  {genre}: {avg_rating:.2f} ({count} movies)\")\n",
    "    \n",
    "    # Show highly rated movies\n",
    "    high_rated = user_movies[user_movies['rating'] >= 4].sort_values('rating', ascending=False)\n",
    "    print(f\"\\nHighly Rated Movies (4+ stars):\")\n",
    "    for _, movie in high_rated.head(5).iterrows():\n",
    "        print(f\"  ⭐ {movie['rating']:.1f} - {movie['title']} [{movie['genres']}]\")\n",
    "    \n",
    "    # Get content-based recommendations\n",
    "    recommendations = content_recommender.recommend(\n",
    "        user_id=user_id, \n",
    "        n_recommendations=n_recommendations\n",
    "    )\n",
    "    \n",
    "    if not recommendations:\n",
    "        print(\"\\nNo recommendations available\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nContent-Based Recommendations:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        title = rec['title']\n",
    "        genres = rec['genres']\n",
    "        score = rec['score']\n",
    "        explanation = rec.get('explanation', '')\n",
    "        avg_rating = rec.get('avg_rating', 0)\n",
    "        \n",
    "        print(f\"{i:2d}. {title}\")\n",
    "        print(f\"    Score: {score:.3f} | Genres: {genres}\")\n",
    "        if avg_rating > 0:\n",
    "            print(f\"    Avg Rating: {avg_rating:.1f}/5.0\")\n",
    "        if explanation:\n",
    "            print(f\"    Why: {explanation}\")\n",
    "        print()\n",
    "\n",
    "# Test with different users\n",
    "test_users = [1, 5, 10]\n",
    "\n",
    "for user_id in test_users:\n",
    "    analyze_user_recommendations(user_id, n_recommendations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance for specific movies\n",
    "def analyze_feature_importance(movie_title, top_n=10):\n",
    "    \"\"\"Analyze most important features for a movie\"\"\"\n",
    "    # Find movie\n",
    "    movie_match = movies_df[movies_df['title'].str.contains(movie_title, case=False, na=False)]\n",
    "    \n",
    "    if movie_match.empty:\n",
    "        print(f\"Movie '{movie_title}' not found\")\n",
    "        return\n",
    "    \n",
    "    movie_id = movie_match.iloc[0]['movieId']\n",
    "    actual_title = movie_match.iloc[0]['title']\n",
    "    \n",
    "    print(f\"\\nFeature Importance for: {actual_title}\")\n",
    "    \n",
    "    # Get feature importance\n",
    "    feature_importance = content_recommender.get_feature_importance(movie_id, top_n=top_n)\n",
    "    \n",
    "    if not feature_importance:\n",
    "        print(\"No feature importance available\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nTop {top_n} Important Features:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for i, (feature, importance) in enumerate(feature_importance, 1):\n",
    "        print(f\"{i:2d}. {feature}: {importance:.4f}\")\n",
    "\n",
    "# Test feature importance for different movies\n",
    "test_movies = [\"Toy Story\", \"Matrix\", \"Pulp Fiction\"]\n",
    "\n",
    "for movie in test_movies:\n",
    "    analyze_feature_importance(movie, top_n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Content-Based Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics for content-based recommendations\n",
    "def evaluate_content_recommendations(sample_users=10, n_recommendations=10):\n",
    "    \"\"\"Evaluate content-based recommendations\"\"\"\n",
    "    \n",
    "    # Sample users with sufficient ratings\n",
    "    user_rating_counts = ratings_df.groupby('userId').size()\n",
    "    active_users = user_rating_counts[user_rating_counts >= 10].index\n",
    "    \n",
    "    if len(active_users) > sample_users:\n",
    "        test_users = np.random.choice(active_users, sample_users, replace=False)\n",
    "    else:\n",
    "        test_users = active_users[:sample_users]\n",
    "    \n",
    "    results = {\n",
    "        'coverage': [],\n",
    "        'diversity': [],\n",
    "        'genre_consistency': []\n",
    "    }\n",
    "    \n",
    "    print(f\"Evaluating content-based recommendations for {len(test_users)} users...\")\n",
    "    \n",
    "    all_movie_ids = set(movies_df['movieId'])\n",
    "    recommended_movies = set()\n",
    "    \n",
    "    for user_id in test_users:\n",
    "        # Get user's genre preferences\n",
    "        user_ratings = ratings_df[ratings_df['userId'] == user_id]\n",
    "        user_movies = user_ratings.merge(movies_df, on='movieId')\n",
    "        \n",
    "        # Calculate user's favorite genres\n",
    "        user_genres = set()\n",
    "        for _, movie in user_movies[user_movies['rating'] >= 4].iterrows():\n",
    "            user_genres.update(parse_genres(movie['genres']))\n",
    "        \n",
    "        # Get recommendations\n",
    "        recommendations = content_recommender.recommend(\n",
    "            user_id=user_id, \n",
    "            n_recommendations=n_recommendations\n",
    "        )\n",
    "        \n",
    "        if not recommendations:\n",
    "            continue\n",
    "        \n",
    "        rec_movie_ids = [rec['movieId'] for rec in recommendations]\n",
    "        recommended_movies.update(rec_movie_ids)\n",
    "        \n",
    "        # Calculate genre consistency\n",
    "        rec_genres = set()\n",
    "        for rec in recommendations:\n",
    "            rec_genres.update(parse_genres(rec.get('genres', '')))\n",
    "        \n",
    "        if user_genres and rec_genres:\n",
    "            genre_overlap = len(user_genres.intersection(rec_genres)) / len(user_genres.union(rec_genres))\n",
    "            results['genre_consistency'].append(genre_overlap)\n",
    "        \n",
    "        # Calculate diversity (average pairwise distance)\n",
    "        if len(recommendations) > 1:\n",
    "            diversities = []\n",
    "            for i in range(len(recommendations)):\n",
    "                for j in range(i+1, len(recommendations)):\n",
    "                    genres1 = set(parse_genres(recommendations[i].get('genres', '')))\n",
    "                    genres2 = set(parse_genres(recommendations[j].get('genres', '')))\n",
    "                    \n",
    "                    if genres1 or genres2:\n",
    "                        jaccard_sim = len(genres1.intersection(genres2)) / len(genres1.union(genres2)) if genres1.union(genres2) else 0\n",
    "                        diversity = 1 - jaccard_sim\n",
    "                        diversities.append(diversity)\n",
    "            \n",
    "            if diversities:\n",
    "                results['diversity'].append(np.mean(diversities))\n",
    "    \n",
    "    # Calculate coverage\n",
    "    catalog_coverage = len(recommended_movies) / len(all_movie_ids)\n",
    "    results['coverage'] = catalog_coverage\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nContent-Based Recommendation Evaluation Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Catalog Coverage: {catalog_coverage:.3f} ({len(recommended_movies)} / {len(all_movie_ids)} movies)\")\n",
    "    \n",
    "    if results['diversity']:\n",
    "        avg_diversity = np.mean(results['diversity'])\n",
    "        print(f\"Average Diversity: {avg_diversity:.3f} (higher is better)\")\n",
    "    \n",
    "    if results['genre_consistency']:\n",
    "        avg_consistency = np.mean(results['genre_consistency'])\n",
    "        print(f\"Genre Consistency: {avg_consistency:.3f} (higher is better)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = evaluate_content_recommendations(sample_users=15, n_recommendations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Comparison of Different Content Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different feature combinations\n",
    "def compare_content_features():\n",
    "    \"\"\"Compare different content-based approaches\"\"\"\n",
    "    \n",
    "    configurations = [\n",
    "        {'use_genres': True, 'use_titles': False, 'name': 'Genres Only'},\n",
    "        {'use_genres': False, 'use_titles': True, 'name': 'Titles Only'},\n",
    "        {'use_genres': True, 'use_titles': True, 'name': 'Genres + Titles'}\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Test movie for similarity\n",
    "    test_movie_id = movies_df[movies_df['title'].str.contains('Toy Story', case=False)].iloc[0]['movieId']\n",
    "    \n",
    "    print(\"Comparing different content feature configurations...\\n\")\n",
    "    \n",
    "    for config in configurations:\n",
    "        print(f\"Testing: {config['name']}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Create and train recommender\n",
    "        recommender = ContentBasedRecommender()\n",
    "        recommender.fit(\n",
    "            ratings_df, \n",
    "            movies_df, \n",
    "            use_genres=config['use_genres'],\n",
    "            use_titles=config['use_titles']\n",
    "        )\n",
    "        \n",
    "        # Get similar movies\n",
    "        similar_movies = recommender.recommend(\n",
    "            movie_id=test_movie_id, \n",
    "            n_recommendations=5\n",
    "        )\n",
    "        \n",
    "        print(f\"Similar to 'Toy Story':\")\n",
    "        for i, movie in enumerate(similar_movies[:5], 1):\n",
    "            print(f\"  {i}. {movie['title']} (sim: {movie['score']:.3f})\")\n",
    "        \n",
    "        # Calculate average similarity\n",
    "        if similar_movies:\n",
    "            avg_similarity = np.mean([m['score'] for m in similar_movies])\n",
    "            print(f\"Average similarity: {avg_similarity:.3f}\")\n",
    "            results[config['name']] = avg_similarity\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # Visualize comparison\n",
    "    if results:\n",
    "        methods = list(results.keys())\n",
    "        scores = list(results.values())\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(methods, scores, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "        plt.title('Content-Based Feature Comparison\\n(Average Similarity Scores for \"Toy Story\")')\n",
    "        plt.ylabel('Average Similarity Score')\n",
    "        plt.ylim(0, max(scores) * 1.1)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, score in zip(bars, scores):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                    f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run comparison\n",
    "feature_comparison = compare_content_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Key Findings and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CONTENT-BASED FILTERING ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n🎯 KEY FINDINGS:\")\n",
    "\n",
    "# Dataset characteristics\n",
    "n_genres = len(get_unique_genres(movies_df))\n",
    "avg_genres_per_movie = movies_enhanced['genre_list'].apply(len).mean()\n",
    "\n",
    "print(f\"\\n📊 Dataset Characteristics:\")\n",
    "print(f\"   • {n_genres} unique genres available for content analysis\")\n",
    "print(f\"   • Average {avg_genres_per_movie:.1f} genres per movie\")\n",
    "print(f\"   • Rich genre information enables effective content-based filtering\")\n",
    "\n",
    "# Feature effectiveness\n",
    "if feature_comparison:\n",
    "    best_config = max(feature_comparison, key=feature_comparison.get)\n",
    "    best_score = feature_comparison[best_config]\n",
    "    \n",
    "    print(f\"\\n🔍 Feature Effectiveness:\")\n",
    "    print(f\"   • Best configuration: {best_config} (score: {best_score:.3f})\")\n",
    "    print(f\"   • Genre information provides strong content signals\")\n",
    "    print(f\"   • Title words add contextual information\")\n",
    "    print(f\"   • Combined features offer balanced recommendations\")\n",
    "\n",
    "# Model performance\n",
    "if evaluation_results:\n",
    "    print(f\"\\n📈 Model Performance:\")\n",
    "    print(f\"   • Catalog coverage: {evaluation_results['coverage']:.1%}\")\n",
    "    \n",
    "    if evaluation_results['diversity']:\n",
    "        avg_div = np.mean(evaluation_results['diversity'])\n",
    "        print(f\"   • Average recommendation diversity: {avg_div:.3f}\")\n",
    "    \n",
    "    if evaluation_results['genre_consistency']:\n",
    "        avg_cons = np.mean(evaluation_results['genre_consistency'])\n",
    "        print(f\"   • Genre consistency with user preferences: {avg_cons:.3f}\")\n",
    "\n",
    "print(f\"\\n💡 RECOMMENDATIONS:\")\n",
    "print(f\"   • Use combined genre + title features for balanced recommendations\")\n",
    "print(f\"   • Weight genres more heavily as they provide stronger content signals\")\n",
    "print(f\"   • Content-based filtering works well for users with clear genre preferences\")\n",
    "print(f\"   • Combine with collaborative filtering to address content limitations\")\n",
    "print(f\"   • Consider movie metadata (year, director, cast) for enhanced content features\")\n",
    "\n",
    "print(f\"\\n🔄 NEXT STEPS:\")\n",
    "print(f\"   • Implement collaborative filtering for comparison\")\n",
    "print(f\"   • Develop hybrid approach combining content and collaborative methods\")\n",
    "print(f\"   • Evaluate recommendations using offline metrics (precision, recall)\")\n",
    "print(f\"   • Test with larger datasets and more diverse content features\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✅ Content-based filtering analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}